---
## DBLab - Aurora Development and Testing Features
## Base Template
##
## Changelog:
## 2018-11-06 - Initial release
## 2018-11-09 - New CFN capabilities
## 2018-11-09 - Added native Perf. Insights support
## 2018-11-09 - added backtrack support and cloudwatch logging
## 2018-11-14 - added KMS permissions to bastion host role
## 2018-11-15 - added support for additional regions
## 2020-06-18 - porting for Aurora BJS LAB
##
## Dependencies:
## none

AWSTemplateFormatVersion: 2010-09-09
Description: DBLab - Aurora Development and Testing Features

## Parameters
Parameters:
  ec2KeyPair:
    Type: AWS::EC2::KeyPair::KeyName
    Description: EC2 key pair for instance access


## Mappings
Mappings:
  RegionalSettings:
   # eu-west-1:
   # bastionAmi: ami-00035f41c82244dab
   # bastionType: m4.large
   # nodeType: db.r4.large
   # eu-central-1:
   # bastionAmi: ami-0bdf93799014acdc4
   # bastionType: m4.large
   # nodeType: db.r4.large
   # ap-southeast-1:
   # bastionAmi: ami-0c5199d385b432989
   # bastionType: m4.large
  #  nodeType: db.r4.large
    cn-north-1:
      bastionAmi: ami-0223ffddc3c2c8220
      bastionType: m4.large
      nodeType: db.r5.large
  NetworkSettings:
    global:
      vpcCidr: 172.31.0.0/16
      subPub1Cidr: 172.31.0.0/24
      subPub2Cidr: 172.31.1.0/24
      subPub3Cidr: 172.31.2.0/24
      subPrv1Cidr: 172.31.10.0/24
      subPrv2Cidr: 172.31.11.0/24
      subPrv3Cidr: 172.31.12.0/24
      sshSourceCidr: 0.0.0.0/0
  ClusterSettings:
    global:
      masterUser: masteruser
      masterPassword: Password1
      dbSchema: mylab
      dbDriver: mysql
    scaling:
      maxCapacity: 2
      minCapacity: 1
      cpuLoadTarget: 20
    sysbench:
      dbSchema: sbtpcc
      runTime: '300'
      numThreads: '4'
      numTables: '8'
      numWarehouses: '2'


## Resources
Resources:

## The VPC
  vpc:
    Type: AWS::EC2::VPC
    Properties:
      EnableDnsSupport: true
      EnableDnsHostnames: true
      InstanceTenancy: default
      CidrBlock: !FindInMap [ NetworkSettings, global, vpcCidr ]
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-vpc

## Create an IGW & attach it to the VPC
  vpcIgw:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-igw
  attachIgwVpc:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref vpc
      InternetGatewayId: !Ref vpcIgw

## Create a public subnet in each AZ
  sub1Public:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, global, subPub1Cidr ]
      AvailabilityZone: !Sub ${AWS::Region}a
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-pub-sub-1
  sub2Public:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, global, subPub2Cidr ]
      AvailabilityZone: !Sub ${AWS::Region}b
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-pub-sub-2
  #sub3Public:
  #  Type: AWS::EC2::Subnet
   # Properties:
   #   VpcId: !Ref vpc
    #  CidrBlock: !FindInMap [ NetworkSettings, global, subPub3Cidr ]
   #   AvailabilityZone: !Sub ${AWS::Region}c
   #   MapPublicIpOnLaunch: true
   #   Tags:
    #    - Key: Name
    #      Value: !Sub ${AWS::StackName}-pub-sub-3

## Associate the public subnets with a public route table
  rtbPublic:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref vpc
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-public-rtb
  rteToIgw:
    Type: AWS::EC2::Route
    DependsOn: attachIgwVpc
    Properties:
      RouteTableId: !Ref rtbPublic
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref vpcIgw
  srta1Public:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub1Public
      RouteTableId: !Ref rtbPublic
  srta2Public:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub2Public
      RouteTableId: !Ref rtbPublic
  #srta3Public:
   # Type: AWS::EC2::SubnetRouteTableAssociation
  #  Properties:
   #   SubnetId: !Ref sub3Public
  #    RouteTableId: !Ref rtbPublic

## Create a private subnet in each AZ
  sub1Private:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, global, subPrv1Cidr ]
      AvailabilityZone: !Sub ${AWS::Region}a
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-prv-sub-1
  sub2Private:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref vpc
      CidrBlock: !FindInMap [ NetworkSettings, global, subPrv2Cidr ]
      AvailabilityZone: !Sub ${AWS::Region}b
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-prv-sub-2
  #sub3Private:
   # Type: AWS::EC2::Subnet
   # Properties:
    #  VpcId: !Ref vpc
   #   CidrBlock: !FindInMap [ NetworkSettings, global, subPrv3Cidr ]
    #  AvailabilityZone: !Sub ${AWS::Region}c
   #   MapPublicIpOnLaunch: false
   #   Tags:
   #     - Key: Name
   #       Value: !Sub ${AWS::StackName}-prv-sub-3

## Create a NAT Gateway & EIP
  natEip:
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc
  vpcNgw:
    Type: AWS::EC2::NatGateway
    DependsOn: attachIgwVpc
    Properties:
      AllocationId: !GetAtt natEip.AllocationId
      SubnetId: !Ref sub2Public

## Associate the private subnets with a NATed route table
  rtbNat:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref vpc
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-nat-rtb
  rteToNgw:
    Type: AWS::EC2::Route
    DependsOn: vpcNgw
    Properties:
      RouteTableId: !Ref rtbNat
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref vpcNgw
  srta1Ngw:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub1Private
      RouteTableId: !Ref rtbNat
  srta2Ngw:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref sub2Private
      RouteTableId: !Ref rtbNat
  #srta3Ngw:
   # Type: AWS::EC2::SubnetRouteTableAssociation
   # Properties:
   #   SubnetId: !Ref sub3Private
   #   RouteTableId: !Ref rtbNat

## Create VPC S3 endpoint
  s3Enpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcId: !Ref vpc
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      RouteTableIds:
        - !Ref rtbPublic
        - !Ref rtbNat
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Principal: '*'
            Effect: 'Allow'
            Action: 's3:*'
            Resource: [ 'arn:aws-cn:s3:::*', 'arn:aws-cn:s3:::*/*' ]

## Create DB subnet group
  dbSubnets:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: !Sub ${AWS::StackName}-db-subnet-group
      SubnetIds: [ !Ref sub1Private, !Ref sub2Private ]
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-db-subnet-group

## Create bastion security group
  bastionSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref vpc
      GroupName: !Sub ${AWS::StackName}-bastion-host
      GroupDescription: Aurora Lab SSH Security Group
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: !FindInMap [ NetworkSettings, global, sshSourceCidr ]
          Description: Allows SSH access from anywhere

## Create DB security group
  dbSecGroupCluster:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref vpc
      GroupDescription: Aurora Lab Database Firewall
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-mysql-internal
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          SourceSecurityGroupId: !Ref bastionSecGroup
          Description: Allows MySQL access from bastion host

## Create enhanced monitoring role
  roleEnhancedMonitoring:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-monitor-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Principal:
              Service:
                - monitoring.rds.amazonaws.com
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole

## Create external integration role
  roleServiceIntegration:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-integrate-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Principal:
              Service:
                - rds.amazonaws.com
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - s3:ListBucket
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:AbortMultipartUpload
                  - s3:DeleteObject
                  - s3:ListMultipartUploadParts
                  - s3:PutObject
                Resource:
                  - !Sub arn:aws-cn:s3:::*/*
                  - !Sub arn:aws-cn:s3:::*

## Create role for bastion host
  roleBastionHost:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-bastion-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 'sts:AssumeRole'
            Principal:
              Service:
                - 'ec2.amazonaws.com.cn'
                - 'ssm.amazonaws.com'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM'
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - rds:*
                  - s3:*
                  - ssm:*
                  - kms:*
                Resource: "*"
  profileBastionHost:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - Ref: roleBastionHost

## Create the bastion host
  bastionHost:
    Type: AWS::EC2::Instance
    Properties:
      SubnetId: !Ref sub1Public
      InstanceType: !FindInMap [ RegionalSettings, !Ref "AWS::Region", bastionType ]
      SecurityGroupIds: [ !Ref bastionSecGroup ]
      KeyName: !Ref ec2KeyPair
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-bastion-host
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            DeleteOnTermination: true
            Iops: 7500
            VolumeSize: 150
            VolumeType: io1
      ImageId: !FindInMap [ RegionalSettings, !Ref "AWS::Region", bastionAmi ]
      IamInstanceProfile: !Ref profileBastionHost
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -xe

          # update & upgrade packages
          #apt-get update
          #DEBIAN_FRONTEND=noninteractive apt-get -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" dist-upgrade
          #echo "* updated and upgraded packages" >> /debug.log

          # install mysql client tools
          #apt-get -y install mysql-client
          #mysql --version >> /debug.log
          #echo "* installed mysql-client package" >> /debug.log

          # install sysbench
          #curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.deb.sh | sudo bash
          #apt-get update
          #apt-get -y install sysbench
          #sysbench --version >> /debug.log
          #echo "* installed sysbench package" >> /debug.log

          # install percona tpcc-like test suite
          #git clone https://github.com/Percona-Lab/sysbench-tpcc.git /home/ubuntu/sysbench-tpcc
          #chown -R ubuntu:ubuntu /home/ubuntu/sysbench-tpcc
          #echo "* cloned percona/sysbench-tpcc repo" >> /debug.log

          # download demo databases
          #git clone https://github.com/datacharmer/test_db.git /home/ubuntu/samples
          #chown -R ubuntu:ubuntu /home/ubuntu/samples
          #echo "* cloned test databases repo" >> /debug.log

          # install python pip and aws cli
          #apt-get -y install python-pip 
          #pip install mysql-connector
          #python -m pip install mysql-connector -i https://pypi.mirrors.ustc.edu.cn/simple/ 
          #apt -y install awscli 
          #cd /home/ubuntu
          #curl -O https://s3-us-west-2.amazonaws.com/auroraworkshopassets/labs/aurora_mysql_dev_test/scripts/loadtest.py  
          #curl -O https://s3-us-west-2.amazonaws.com/auroraworkshopassets/labs/aurora_mysql_dev_test/scripts/ImportFromS3.sql
          #chown -R ubuntu:ubuntu /home/ubuntu/loadtest.py
          #chown -R ubuntu:ubuntu /home/ubuntu/ImportFromS3.sql
          #echo "* pulled load test script" >> /debug.log

          # reboot
          echo "* bootstrap complete, rebooting" >> /debug.log
          shutdown -r now

## Create parameter groups for cluster nodes
  pgNodeParams:
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Description: !Sub ${AWS::StackName}-node-params
      Family: aurora-mysql5.7
      Parameters:
        innodb_stats_persistent_sample_pages: 256
        slow_query_log: 1
        long_query_time: 10
        log_output: FILE
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-node-params

## Create cluster parameter group
  cpgClusterParams:
    Type: AWS::RDS::DBClusterParameterGroup
    Properties:
      Description: !Sub ${AWS::StackName}-cluster-params
      Family: aurora-mysql5.7
      Parameters:
        aws_default_s3_role: !GetAtt roleServiceIntegration.Arn
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-cluster-params

## Create Aurora cluster
  dbCluster:
    Type: AWS::RDS::DBCluster
    Properties:
      Engine: aurora-mysql
      DBSubnetGroupName: !Ref dbSubnets
      DBClusterParameterGroupName: !Ref cpgClusterParams
      DBClusterIdentifier: !Sub ${AWS::StackName}-cluster
      BackupRetentionPeriod: 7
      MasterUsername: !FindInMap [ ClusterSettings, global, masterUser ]
      MasterUserPassword: !FindInMap [ ClusterSettings, global, masterPassword ]
      DatabaseName: !FindInMap [ ClusterSettings, global, dbSchema ]
      StorageEncrypted: true
      VpcSecurityGroupIds: [ !Ref dbSecGroupCluster ]
      EnableCloudwatchLogsExports: [ error, slowquery ]
      #BacktrackWindow: 86400
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-cluster

## Create role for use with role assignment to Aurora cluster and log export via custom resource
  roleClusterEnhancements:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-cluster-changes-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Principal:
              Service:
                - lambda.amazonaws.com
      Policies:
        - PolicyName: inline-policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: 'arn:aws-cn:logs:*:*:*'
              - Effect: Allow
                Action:
                  - rds:AddRoleToDBCluster
                  - rds:RemoveRoleFromDBCluster
                  - rds:DescribeDBClusters
                Resource: '*'
              - Effect: Allow
                Action:
                  - iam:PassRole
                  - iam:GetRole
                Resource: !GetAtt roleServiceIntegration.Arn

## Create Lambda function to implement role assignment and log export for Aurora cluster
  funcClusterEnhancements:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-cluster-changes
      Description: Custom Resource to assign the IAM roles to an Aurora cluster, and export logs to CloudWatch Logs, since CloudFormation doesn't do it natively
      Handler: index.handler
      Role: !GetAtt roleClusterEnhancements.Arn
      Runtime: python3.6
      Timeout: 30
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-cluster-changes
      Environment:
        Variables:
          REGION: !Ref "AWS::Region"
      Code:
        ZipFile: |
          # Dependencies
          from os import environ
          import cfnresponse
          import boto3

          print("[INFO]", "Initialize function")

          session = boto3.session.Session(region_name=environ["REGION"])
          rds = session.client('rds')

          # Lambda handler function / main function
          def handler(event, context):
              print("[INFO]", "Invocation start")

              # globals
              global rds

              # init response
              response_status = cfnresponse.FAILED
              response_data = {}
              aurora_existing_roles = []
              aurora_new_roles = []

              # try/catch
              try:
                  # get cluster properties
                  aurora_cluster = event["ResourceProperties"]["Cluster"]
                  response = rds.describe_db_clusters(DBClusterIdentifier=aurora_cluster)
                  if "DBClusters" not in response or not response["DBClusters"]:
                      raise ValueError("Cluster does not exist, or bad API response: %s" % aurora_cluster)

                  # get existing role associations
                  if "AssociatedRoles" in response["DBClusters"][0]:
                      for role in response["DBClusters"][0]["AssociatedRoles"]:
                          aurora_existing_roles.append(role["RoleArn"])

                  # get new roles
                  if "Role" in event["ResourceProperties"]:
                      aurora_new_roles.append(event["ResourceProperties"]["Role"])

                  # figure out roles we need to add and delete
                  roles_to_add = set(aurora_new_roles).difference(aurora_existing_roles)
                  roles_to_del = set(aurora_existing_roles).difference(aurora_new_roles)

                  # only make changes if changes are needed
                  if roles_to_add and roles_to_del:
                      # this is currently not well supported by the RDS API (multiple subsequent calls)
                      raise ValueError("Cannot make multiple role changes at once on the cluster: %s" % aurora_cluster)
                  elif len(roles_to_add) > 1 or len(roles_to_del) > 1:
                      # this is currently not well supported by the RDS API (multiple subsequent calls)
                      raise ValueError("Cannot make multiple role changes at once on the cluster: %s" % aurora_cluster)
                  elif roles_to_add or roles_to_del:
                      # deleting roles first
                      for arn in roles_to_del:
                          rds.remove_role_from_db_cluster(DBClusterIdentifier=aurora_cluster, RoleArn=arn)
                          print("[INFO]", "Removed role %s from cluster %s" % (arn, aurora_cluster))

                      # adding new roles
                      for arn in roles_to_add:
                          rds.add_role_to_db_cluster(DBClusterIdentifier=aurora_cluster, RoleArn=arn)
                          print("[INFO]", "Added role %s to cluster %s" % (arn, aurora_cluster))

                  # if we got here, set response to success
                  response_status = cfnresponse.SUCCESS
              except Exception as e:
                  print("[ERROR]", e)

              # try/catch
              try:
                  # send response to CloudFormation
                  cfnresponse.send(event, context, response_status, response_data)
              except Exception as e:
                  print("[ERROR]", e)
                  response_status = cfnresponse.FAILED

              print("[INFO]", "Invocation end")

              return response_status

## Custom resource to assign cluster IAM role
  resClusterEnhancements:
    Type: Custom::resClusterEnhancements
    Properties:
      ServiceToken: !GetAtt funcClusterEnhancements.Arn
      Cluster: !Ref dbCluster
      Role: !GetAtt roleServiceIntegration.Arn

## Deploy the first cluster node (always the writer)
  dbNodeWriter:
    Type: AWS::RDS::DBInstance
    DependsOn: [ resClusterEnhancements ]
    Properties:
      DBClusterIdentifier: !Ref dbCluster
      DBInstanceIdentifier: !Sub ${AWS::StackName}-node-01
      CopyTagsToSnapshot: true
      DBInstanceClass: !FindInMap [ RegionalSettings, !Ref "AWS::Region", nodeType ]
      DBParameterGroupName: !Ref pgNodeParams
      Engine: aurora-mysql
     # MonitoringInterval: 1
     # MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-node-01

## Deploy a reader node
  dbNodeSecondary:
    Type: AWS::RDS::DBInstance
    DependsOn: [ dbNodeWriter ]
    Properties:
      DBClusterIdentifier: !Ref dbCluster
      DBInstanceIdentifier: !Sub ${AWS::StackName}-node-02
      CopyTagsToSnapshot: true
      DBInstanceClass: !FindInMap [ RegionalSettings, !Ref "AWS::Region", nodeType ]
      DBParameterGroupName: !Ref pgNodeParams
      Engine: aurora-mysql
     # MonitoringInterval: 1
     # MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: false
     # EnablePerformanceInsights: true
     # PerformanceInsightsRetentionPeriod: 7
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-node-02

## Role to overcome current limitations in CFN ScalableTarget implemetation
## This role is *NOT* actively used by any resource and service, but must be present
  roleScalableTarget:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-aas-target-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Principal:
              Service:
                - rds.application-autoscaling.amazonaws.com

## Register the scalable target
  dbScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    DependsOn: [ dbNodeSecondary ]
    Properties:
      ServiceNamespace: rds
      ScalableDimension: rds:cluster:ReadReplicaCount
      ResourceId: !Sub cluster:${dbCluster}
      MaxCapacity: !FindInMap [ ClusterSettings, scaling, maxCapacity ]
      MinCapacity: !FindInMap [ ClusterSettings, scaling, minCapacity ]
      RoleARN: !GetAtt roleScalableTarget.Arn

## Add scaling policy
  dbScalingPolicy:
    Type : AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: !Sub ${AWS::StackName}-autoscale-readers
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref dbScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: RDSReaderAverageCPUUtilization
        ScaleInCooldown: 180
        ScaleOutCooldown: 180
        TargetValue: !FindInMap [ ClusterSettings, scaling, cpuLoadTarget ]

## Create sysbench prep SSM document
  ssmDocSysbenchTest:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-sysbench-test
      Content:
        schemaVersion: '2.2'
        description: SysBench Percona TPCC-LIKE Preparation
        parameters:
          clusterEndpoint:
            type: String
            description: Aurora Cluster Endpoint
            default: !GetAtt dbCluster.Endpoint.Address
          dbUser:
            type: String
            description: DB User
            default: !FindInMap [ ClusterSettings, global, masterUser ]
          dbPassword:
            type: String
            description: DB Password
            default: !FindInMap [ ClusterSettings, global, masterPassword ]
          dbSchema:
            type: String
            description: DB Schema
            default: !FindInMap [ ClusterSettings, sysbench, dbSchema ]
          dbDriver:
            type: String
            description: DB Driver
            default: !FindInMap [ ClusterSettings, global, dbDriver ]
            allowedValues: [ mysql, pgsql ]
          runTime:
            type: String
            description: Test Runtime
            default: !FindInMap [ ClusterSettings, sysbench, runTime ]
          numThreads:
            type: String
            description: Threads
            default: !FindInMap [ ClusterSettings, sysbench, numThreads ]
          numTables:
            type: String
            description: Tables
            default: !FindInMap [ ClusterSettings, sysbench, numTables ]
          numScale:
            type: String
            description: Scale
            default: !FindInMap [ ClusterSettings, sysbench, numWarehouses ]
        mainSteps:
        - action: aws:runShellScript
          name: SysBenchTpccPrepare
          inputs:
            runCommand:
            - 'echo "DROP SCHEMA IF EXISTS {{ dbSchema }}; CREATE SCHEMA {{ dbSchema }};" | mysql -h{{ clusterEndpoint }} -u{{ dbUser }} -p{{ dbPassword }} && cd /home/ubuntu/sysbench-tpcc && ./tpcc.lua --mysql-host={{ clusterEndpoint }} --mysql-user={{ dbUser }} --mysql-password={{ dbPassword }} --mysql-db={{ dbSchema }} --threads={{ numThreads }} --tables={{ numTables }} --scale={{ numScale }} --time={{ runTime }} --db-driver={{ dbDriver }} prepare'
        - action: aws:runShellScript
          name: SysBenchTpccRun
          inputs:
            runCommand:
            - 'cd /home/ubuntu/sysbench-tpcc && ./tpcc.lua --mysql-host={{ clusterEndpoint }} --mysql-user={{ dbUser }} --mysql-password={{ dbPassword }} --mysql-db={{ dbSchema }} --threads={{ numThreads }} --tables={{ numTables }} --scale={{ numScale }} --time={{ runTime }} --db-driver={{ dbDriver }} run'


## Outputs
Outputs:
  vpcId:
    Description: Aurora Lab VPC
    Value: !Ref vpc
  bastionEndpoint:
    Description: Bastion Host Endpoint
    Value: !GetAtt bastionHost.PublicDnsName
  bastionInstance:
    Description: Bastion Instance ID
    Value: !Ref bastionHost
  clusterName:
    Description: Cluster Name
    Value: !Ref dbCluster
  clusterEndpoint:
    Description: Aurora Cluster Endpoint
    Value: !GetAtt dbCluster.Endpoint.Address
  readerEndpoint:
    Description: Aurora Reader Endpoint
    Value: !GetAtt dbCluster.ReadEndpoint.Address
  loadTestRunDoc:
    Description: Load Test Execution Command Document
    Value: !Ref ssmDocSysbenchTest
  dbSubnetGroup:
    Description: Database Subnet Group
    Value: !Ref dbSubnets
  dbSecurityGroup:
    Description: Database Security Group
    Value: !Ref dbSecGroupCluster